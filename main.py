from flask import Flask, request, Response
import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse

app = Flask(__name__)

# ‚úÖ Csak ezekb≈ël a domainekb≈ël enged√ºnk tartalmat
MEGBIZHATO_DOMAINNEK = [
    "index.hu", "telex.hu", "444.hu", "bbc.com", "euronews.com",
    "hu.wikipedia.org", "en.wikipedia.org",
    "fandom.com", "gamepedia.com", "minecraft.wiki"
]

# üîç Keres√©s DuckDuckGo seg√≠ts√©g√©vel
def duckduckgo_search(q):
    res = requests.post("https://html.duckduckgo.com/html/", data={"q": q})
    soup = BeautifulSoup(res.text, "html.parser")
    return [a['href'] for a in soup.select('.result__a')]

# üßΩ Letiszt√≠tott sz√∂veg kiszed√©se egy oldalr√≥l
def extract_text(url):
    try:
        domain = urlparse(url).netloc.lower()
        if not any(d in domain for d in MEGBIZHATO_DOMAINNEK):
            return None  # ‚õî Sz≈±r√©s: nem megb√≠zhat√≥

        print("‚úÖ Elfogadott domain:", domain)
        r = requests.get(url, timeout=10)
        soup = BeautifulSoup(r.text, "html.parser")
        paragraphs = [p.get_text(strip=True) for p in soup.find_all("p")]
        clean_text = "\n".join(paragraphs)
        return f"Forr√°s: {url}\n\n{clean_text}\n"
    except Exception as e:
        print("‚ùå Hiba cikk let√∂lt√©sekor:", e)
        return None

@app.route("/search")
def search():
    query = request.args.get("q", "")
    links = duckduckgo_search(query)
    texts = []

    for url in links:
        text = extract_text(url)
        if text:
            texts.append(text)
        if len(texts) >= 2:
            break  # max 2 megb√≠zhat√≥ forr√°s

    if not texts:
        return Response("Nem tal√°ltam megb√≠zhat√≥ inform√°ci√≥t.", mimetype="text/plain")

    full_text = "\n\n---\n\n".join(texts)
    return Response(full_text, mimetype="text/plain")

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port)
